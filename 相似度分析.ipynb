{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "from gensim.models import word2vec\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "def get_data():\n",
    "\tcomment_data=pd.read_excel('评论数据.xls')\n",
    "\treturn comment_data.loc[:,['hotelid','content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立中文停用词表 返回list格式\n",
    "def get_stop_words():\n",
    "\tchinese_stop_words=[]\n",
    "\tfor line in open(\"chinese_stop_words.txt\",'r'):\n",
    "\t\tchinese_stop_words.append(line[:-1])\n",
    "\treturn chinese_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分词，以list形式返回结果\n",
    "def segment_word(comment_data,chinese_stop_words):\n",
    "\tsentences=[]\n",
    "\tfor comment in comment_data:\n",
    "\t\tseg_word=list(jieba.cut(str(comment)))\n",
    "\t\tkeywords_list=[]\n",
    "\t\tfor s_w in seg_word:\n",
    "\t\t\tif s_w not in chinese_stop_words:  \n",
    "\t\t\t\tif s_w != '\\t':\n",
    "\t\t\t\t\tkeywords_list.append(s_w)\n",
    "\t\tsentences.append(keywords_list)\n",
    "\treturn sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算某个词的相关词列表（包括正面与负面）\n",
    "def related_list(model,word):\n",
    "    items1 = model.most_similar(positive=[word],topn=20)\n",
    "    items2 = model.most_similar(negative=[word],topn=20)\n",
    "    df1 = pd.DataFrame(items1, columns=['词', '相似度'])\n",
    "    df2 = pd.DataFrame(items2, columns=['词', '相似度'])\n",
    "    df=pd.concat([df1,df2])\n",
    "    df = df.reindex(columns=['原词','词', '相似度'],fill_value=word)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成酒店相关评价列表\n",
    "def related_list_all(model):\n",
    "    key_words=['服务','房间','环境','位置','交通','性价比','早餐','价格']\n",
    "    df=pd.DataFrame(columns=['原词','词', '相似度'])\n",
    "    for word in key_words:\n",
    "        df_sub=related_list(model,word)\n",
    "        df=pd.concat([df,df_sub])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2018-11-16 11:06:51,406 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "2018-11-16 11:06:51,409 : DEBUG : Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.723 seconds.\n",
      "2018-11-16 11:06:52,131 : DEBUG : Loading model cost 0.723 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2018-11-16 11:06:52,133 : DEBUG : Prefix dict has been built succesfully.\n",
      "2018-11-16 11:07:03,898 : INFO : collecting all words and their counts\n",
      "2018-11-16 11:07:03,899 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-11-16 11:07:03,920 : INFO : PROGRESS: at sentence #10000, processed 105225 words, keeping 10092 word types\n",
      "2018-11-16 11:07:03,944 : INFO : collected 16423 word types from a corpus of 213741 raw words and 17909 sentences\n",
      "2018-11-16 11:07:03,945 : INFO : Loading a fresh vocabulary\n",
      "2018-11-16 11:07:03,955 : INFO : min_count=10 retains 2245 unique words (13% of original 16423, drops 14178)\n",
      "2018-11-16 11:07:03,956 : INFO : min_count=10 leaves 182995 word corpus (85% of original 213741, drops 30746)\n",
      "2018-11-16 11:07:03,965 : INFO : deleting the raw counts dictionary of 16423 items\n",
      "2018-11-16 11:07:03,966 : INFO : sample=0.001 downsamples 65 most-common words\n",
      "2018-11-16 11:07:03,967 : INFO : downsampling leaves estimated 143064 word corpus (78.2% of prior 182995)\n",
      "2018-11-16 11:07:03,983 : INFO : estimated required memory for 2245 words and 2048 dimensions: 37904580 bytes\n",
      "2018-11-16 11:07:03,984 : INFO : resetting layer weights\n",
      "2018-11-16 11:07:04,067 : INFO : training model with 3 workers on 2245 vocabulary and 2048 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-16 11:07:04,640 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-16 11:07:04,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-16 11:07:04,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-16 11:07:04,672 : INFO : EPOCH - 1 : training on 213741 raw words (143067 effective words) took 0.6s, 239333 effective words/s\n",
      "2018-11-16 11:07:05,250 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-16 11:07:05,254 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-16 11:07:05,266 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-16 11:07:05,267 : INFO : EPOCH - 2 : training on 213741 raw words (143258 effective words) took 0.6s, 243447 effective words/s\n",
      "2018-11-16 11:07:05,759 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-16 11:07:05,761 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-16 11:07:05,781 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-16 11:07:05,783 : INFO : EPOCH - 3 : training on 213741 raw words (143006 effective words) took 0.5s, 281711 effective words/s\n",
      "2018-11-16 11:07:06,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-16 11:07:06,298 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-16 11:07:06,311 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-16 11:07:06,312 : INFO : EPOCH - 4 : training on 213741 raw words (142761 effective words) took 0.5s, 274423 effective words/s\n",
      "2018-11-16 11:07:06,831 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-16 11:07:06,840 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-16 11:07:06,842 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-16 11:07:06,843 : INFO : EPOCH - 5 : training on 213741 raw words (142957 effective words) took 0.5s, 274521 effective words/s\n",
      "2018-11-16 11:07:06,843 : INFO : training on a 1068705 raw words (715049 effective words) took 2.8s, 257583 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# 主程序\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "comment_data=get_data()\n",
    "chinese_stop_words=get_stop_words()\n",
    "sentences=segment_word(comment_data.content,chinese_stop_words)\n",
    "model = word2vec.Word2Vec(sentences, size=2048, min_count=10) # 默认window=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df=related_list_all(model)\n",
    "df.to_csv('所有酒店相似度分析.csv',encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \n",
      "2018-11-16 11:07:06,851 : INFO : precomputing L2-norms of word weight vectors\n",
      "2018-11-16 11:07:06,898 : WARNING : vectors for words {'很'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'服务'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 寻找不合群的词\n",
    "y2 = model.doesnt_match(u\"酒店 服务 很\".split())\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型，以便重用\n",
    "#model.save(u\"酒店评论.model\")\n",
    "# # 对应的加载方式\n",
    "#model = word2vec.Word2Vec.load(\"酒店评论.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
